All discussed algorithms and the other cograph recognition algorithm \cite{Habib2005ASL} were implemented and added to the Koala-NetworKit library \cite{Tur+23}. They were implemented in C++ using the NetworKit \cite{NKT+23} library and
the Koala \cite{Tur+23} library. 

\section{Implementation details}
Let us show the file structure. 

\textbf{CoTree files:}
\begin{itemize}
    \item \texttt{include/recognition/CoTree.hpp} -- header file, which defines cotree interface
    \item \texttt{cpp/recognition/cograph/CoTree.cpp} -- implementation of cotree interface
\end{itemize}
\textbf{Cograph recognition algorithm files:}
\begin{itemize}
    \item \texttt{include/recognition/CographRecognition.hpp} -- main header file, which defines default cograph recognition and other algorithm interfaces.
    \item \texttt{cpp/recognition/CographRecognition.cpp} -- implementation of default cograph recognition algorithms' interfaces.
    \item \texttt{cpp/recognition/cograph/CorneilStewartPerlCographRecognition.cpp} -- Corneil, Perl and Stewart algorithm implementation.
\item \texttt{cpp/recognition/cograph/BretscherCorneilHabibPaulCographRecognition.cpp} -- Bretscher, Corneil, Habib, Paul algorithm implemenation.
\item \texttt{cpp/recognition/cograph/DahlhausCographRecognition.cpp} -- Dahlhaus algoritm implementation.
\item \texttt{benchmark/benchmarkCographs.cpp} -- benchmarking programs to evaluate the correctness of every algorithm on different graphs.
\item \texttt{test/testCographRecognition.cpp} -- unit tests for evaluating the correctness of every algorithm.
\end{itemize}


\section{Benchmarking and performance evaluation}
Our benchmarking suite allows for a robust assessment of algorithm correctness and performance, testing on randomly generated graphs, as well as on all known fixed-size graphs and cographs and comparing the results.

The performance of the algorithms was thoroughly evaluated across a wide range of graph instances. By testing graphs of varying sizes and densities, we assessed the efficiency of each algorithm in different scenarios.  \Cref{tab:algorithms_number} displays the identifier assigned to each algorithm in the tables below.

We choose four random graph models for performance testing:
\begin{itemize}
    \item Erd\H{o}s-Renyi model --  it provides a wide variety of graph structures, ensuring comprehensive testing across different configurations of node connections. It is a standard model for testing graph algorithms,
    \item Barab\'asi-Albert model -- it produces a network with a few vertices of high degree and many vertices of low degree. If we initiate our algorithm with vertices of low degree, the algorithm can terminate much sooner than if we start with vertices of high degree. For instance, $A1$ is iterative and its performance is significantly influenced by the degrees of the processed vertices. So, this test allows us to obtain the ``best case'' scenario.
    \item Watts-Strogatz model -- all vertex degrees are identical and all paths are short, providing a more useful test than the previous one, allowing us to obtain the ``average'' scenario.
    \item Randomly generated cographs -- unlike graphs that are not cographs, the execution of the algorithms on a cograph cannot end earlier with a result ``not a cograph''. Therefore, this test allows us to maintain the ``worst-case'' scenario. 
\end{itemize}

All restrictions follow from the capabilities of the algorithms or the capabilities of the generator functions, some of which end with a SIGKILL error or hang due to large input data. Generators work longer than all algorithms. For each data set, only one graph was tested, since generating such large data is very time-consuming.
\begin{center}
\begin{table}[]
    \centering
    \begin{tabular}{ | c | p{10cm} |}
  \hline
  Number & Algorithm \\ [0.5ex] 
  \hline\hline
  $A1$ & A linear recognition algorithm for cographs by Corneil, Perl, Stewart \cite{corneil_perl_stewart_85} \\
  \hline
  $A2$ & A simple Linear Time LexBFS Cograph Recognition Algorithm by Bretscher, Corneil, Habib, Paul \cite{Bretscher2003ASL}\\
  \hline
  $A3$ & Efficient parallel recognition algorithms of and distance hereditary graphs by Dahlhaus \cite{dahlhaus_95}\\
  \hline
  $A4$ & A simple linear time algorithm for cograph recognition by Habib, Paul \cite{Habib2005ASL}\\
  \hline
  \end{tabular}
  \caption{The algorithms with their identifiers}
    \label{tab:algorithms_number}
\end{table}
  \end{center}

\section{Erd\H{o}s-Reny\'\i\  model}
The Erd\H{o}s-Reny\'\i\ model, denoted as $G(n,p)$ is a random graph model used to generate graphs with a given number of nodes $n$ and probability $p$. Each edge is added to the resulting graph with a probability of $p$. Every edge addition is independent from the other edges additions. 

The \Cref{tab:erdos_renyi} below shows the results for graphs randomly generated by this model. 
\begin{center}
\begin{table}[]
    \centering
    \begin{tabular}[
    caption = {Erdos-Renyi model},
    label = {tbl:erdos_renyi},
  ]{ | c | c | c | c | c | c | c | }
  \hline
     $n$ & $p$ & $m$ & $A1$ & $A2$ & $A3$ & $A4$ \\ [0.5ex] 
  \hline\hline
   10000 & 0.1 & 4997813 & 897 & 116567 & 3643 & 129 \\
  \hline
 10000 & 0.3 & 15001181 & 2350 & 926327 & 4719 & 436 \\
\hline
 10000 & 0.5 & 24997283 & 3392 & >1000000 & 5654 & 680 \\
\hline
 10000 & 0.7 & 34997994 & 4036 & >1000000 & 8650 & 960 \\
\hline
 10000 & 0.9 & 44994097 & 4998 & > 1000000 & 27986 & 1122 \\
  \hline
  \end{tabular}
  \caption{The running time for the Erd\H{o}s-Reny\'\i\ model(time in ms)}
    \label{tab:erdos_renyi}
\end{table}
\end{center}
\section{Barab\'asi-Albert model}
The Barab\'asi-Albert model generates scale-free networks using a preferential attachment mechanism. It starts with a small connected network, forming connections to existing nodes, one node at a time. The probability of connecting to a particular existing node is proportional to its degree, meaning that nodes with higher degrees are more likely to receive new links. The parameters for this model are the number of vertices $n$ and the number of attachments per node $k$.

The \Cref{tab:barabasi_albert} below shows the results for graphs randomly generated by this model. 
\begin{center}
\begin{table}[]
    \centering
    \begin{tabular}[
    caption = {Barabasi-Albert model},
    label = {tbl:barabasi_albert},
  ]{ | c | c | c | c | c | c | c | }
  \hline
   $n$ & $k$ & $m$ & $A1$ & $A2$ & $A3$ & $A4$ \\ [0.5ex] 
  \hline\hline
   10000 & 10 & 99910 & 35 & 112 & 3 & 5 \\
  \hline
 10000 & 100 & 990100 & 225 & 4405 & 181 & 23 \\
\hline
 10000 & 1000 & 9001000 & 1554 & 269225 & 3313 & 240 \\
\hline
 100000 & 10 & 999910 & 506 & 1609 & 46 & 128 \\
\hline
 100000 & 100 & 9990100 & 4288 & 56588 & 175 & 795 \\
\hline
 100000 & 1000 & 99001000 & 37708 & 4132689 & 31877 & 17512 \\
  \hline
  \end{tabular}
  \caption{The running time for the Barab\'asi-Albert model(time in ms)}
    \label{tab:barabasi_albert}
\end{table}
  \end{center}

\section{Watts-Strogatz model}
The Watts-Strogatz model creates small-world networks that exhibit high clustering and short average path lengths. It starts with a regular lattice where each node is connected to its 
$k$ nearest neighbors. Then, with probability 
$p$, each edge is randomly rewired, introducing shortcuts that reduce the path length between nodes while maintaining the high clustering characteristic. 

The \Cref{tab:watts_strogatz} below shows the results for graphs randomly generated by this model. 

  \begin{center}
  \begin{table}[]
      \centering
    \begin{tabular}[
    caption = {Watts-Strogatz model},
    label = {tbl:watts_strogatz},
  ]{ | c | c | c | c | c | c | c | c |}
  \hline
     $n$ & $k$ & $p$ & $m$ & $A1$ & $A2$ & $A3$ & $A4$ \\ [0.5ex] 
  \hline\hline
   10000 & 40 & 0.1 & 400000 & 41 & 669 & 7 & 10 \\
  \hline
 10000 & 400 & 0.1 & 4000000 & 468 & 65170 & 94 & 106 \\
\hline
 10000 & 4000 & 0.1 & 40000000 & 4637 & 4301795 & 21035 & 958 \\
\hline
 10000 & 40 & 0.7 & 400000 & 96 & 983 & 8 & 10 \\
\hline
 10000 & 400 & 0.7 & 4000000 & 788 & 73502 & 1281 & 94 \\
  \hline
  \end{tabular}
  \caption{The running time for the Watts-Strogatz model(time in ms)}
      \label{tab:watts_strogatz}
  \end{table}
  \end{center}
\section{Random cographs}
Random cographs are generated by applying union and complement operations with given probabilities. We generate $n$ trivial cographs. Next, with a given probability $p$, we choose the complement or union operation. Then we randomly choose a graph or two graphs respectively and do the chosen operation. The results are shown in the \Cref{tab:random_cographs}. 

  \begin{center}
  \begin{table}[]
      \centering
    \begin{tabular}[
    caption = {Random cographs},
    label = {tbl:random_cographs},
  ]{ | c | c | c | c | c | c | c |}
  \hline
   $n$ & $p$ & $m$ & $A1$ & $A2$ & $A3$ & $A4$ \\ [0.5ex] 
 \hline\hline
  1000 & 0.1 & 8508 & 3 & 6 & 5 & 4 \\
 \hline
 1000 & 0.3 & 85975 & 8 & 184 & 24 & 53 \\
\hline
 1000 & 0.5 & 216736 & 20 & 1011 & 24 & 584 \\
\hline
 1000 & 0.7 & 372950 & 37 & 3219 & 49 & 581 \\
\hline
 1000 & 0.9 & 275882 & 27 & 1541 & 61 & 524 \\
\hline
 5000 & 0.1 & 53793 & 142 & 69 & 33 & 57 \\
\hline
 5000 & 0.3 & 241943 & 197 & 1009 & 81 & 256 \\
\hline
 5000 & 0.5 & 5369758 & 865 & 116818 & 1458 & 24276 \\
\hline
5000 & 0.7 & 1554688 & 414 & 13911 & 384 & 3350 \\
\hline
 5000 & 0.9 & 5411969 & 936 & 139731 & 924 & 26561 \\
\hline
10000 & 0.1 & 2311377 & 973 & 34296 & 752 & 8257 \\
\hline
10000 & 0.3 & 22918654 & 3765 & 1418090 & 10427 & 306288 \\
\hline
10000 & 0.5 & 19424286 & 3352 & 830930 & 4376 & 223273 \\
\hline
10000 & 0.7 & 14658457 & 2988 & 633056 & 3020 & 122469 \\
\hline
10000 & 0.9 & 16429436 & 3441 & 682039 & 2606 & 196761 \\
\hline
  \end{tabular}
  \caption{The running time for the random cographs(time in ms)}
      \label{tab:random_cographs}
  \end{table}
  \end{center}

  \section{Conclusion}
  As we can see, $A2$ is quadratic time, since the function hasEdge from \cite{NKT+23} is linear time. If we get rid of this function in favor of a hash table, then $A2$ will be linear time. $A3$ is $O((n+m)\log{n})$, $A1$ and $A4$ are linear time. The results can be explained it the following way. The $A4$ algorithm has a small constant, the other algorithms have significantly larger constants. Additionally, the $A1$ and the $A3$ algorithms tend to terminate before examining every edge and node -- they just told us it is not a cograph already, $A3$ has more such posibilities, so in some cases it is definitely the best. The $A2$ always goes through the entire algorithm and never stops before. 