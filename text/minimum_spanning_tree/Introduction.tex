The minimum spanning problem is one of the simplest and most researched problems in graph algorithms. The task is to for a given connected and weighted graph is to find a spanning tree with a minimum sum of edge weights.

\begin{figure}[ht!]
    \centering
    \begin{tikzpicture}[
        vertex/.style={circle, draw, minimum size=8mm},
        edge/.style={draw, thick}
    ]
        % Nodes
        \node[vertex] (1) {1};
        \node[vertex, right=2cm of 1] (2) {2};
        \node[vertex, below=2cm of 1] (3) {3};
        \node[vertex, right=2cm of 3] (4) {4};

        % Edges
        \draw[edge, red] (1) -- (2) node[midway, above] {\small 1};
        \draw[edge] (1) -- (3) node[midway, left]  {\small 7};
        \draw[edge, red] (2) -- (3) node[midway, right] {\small 5};
        \draw[edge, red] (3) -- (4) node[midway, below] {\small 2};
    \end{tikzpicture}
    \caption{Example graph. Red edges form the minimum spanning tree}
    \label{fig:graph-1}
\end{figure}
\FloatBarrier

It arises naturally when dealing with any kinds of networks like constructing efficient electricity grid \cite{bor} or water supply \cite{water}. It is also used in other algorithms -- image registration \cite{image_registration}, handwriting recognition \cite{handwriting} or in the approximate solution for the traveling salesman problem \cite{salesman}.

Algorithms solving the problem and their analysis are presented in many popular resources such as Cormen et al. textbook ``Introduction to Algorithms'' \cite{cormen}, cp-algorithms website \cite{cpalgoPrim} and a comprehensive overview by Eisner \cite{eisner}.

\section{Problem history}
The minimum spanning tree problem has long and rich history going as far back as 1926 when Borůvka used his algorithm to compute the most efficient electricity network for Moravia \cite{bor}. 

The problem was studied for years since and the most widely known contributions were done by Kruskal in 1956 \cite{kruskal} and Prim in 1957 \cite{prim}. These algorithms solve the problem in a greedy manner. The basic argument behind them is that for each vertex its smallest incident edge has to be the part of the minimum spanning tree. Otherwise, such edge would create a cycle with the minimum spanning tree and on this cycle there would be a larger edge also incident to the same vertex, switching these edges in the spanning tree would make its total weight smaller.

That said each algorithm proceeds differently:
\begin{itemize}
    \item \textbf{Borůvka's algorithm}: This algorithm works in phases, in each phase the smallest incident edge to each vertex in the graph is found and these edges are contracted all at once at the end of the phase. Consecutive phases are run until the graph contracts to one vertex. It is proven to work in $O(m\log{n})$ time.
    
    \item \textbf{Kruskal's algorithm}:
    All of the edges are sorted. A disjoint set union is created with each vertex being a different set. Sorted edges are checked in an ascending order when an edge connects two different sets it get contracted and added to the spanning tree under construction. It is proven to work in $O(m\log{n})$ time if the sorting algorithm is comparison based.
    
    \item \textbf{Prim's algorithm}:
    One vertex is picked. Until all vertices are visited the smallest edge joining visited and unvisited vertices is found. It's unvisited end is visited and it's neighboring edges are added to the priority queue on which the unprocessed edges lie. With a standard heap this algorithm runs in $O(m\log{n})$ time and using more complex structures like Fibonacci heap \cite{FredmanTarjan} its complexity decreases to $O(m  + n\log{n})$.
\end{itemize}

Further contributions include Yao \cite{yao} and Cheriton with Tarjan \cite{cherTarj} who independently found different algorithms with $O(m \log{\log{n}})$ complexity. Later Fredman and Tarjan \cite{FredmanTarjan} lowered the complexity to $O(m \beta(m, n))$ where $\beta(m, n)$ is defined as the number of log iterations necessary to map $n$ to number smaller then $\frac{m}n$ and in the worst case for $m = O(n)$ it is $O(m\log^*{n})$. It was shortly after improved to $O(m\log{\beta(m,n)})$ by Gabow et al. \cite{gabowEtAl}. In 2000 Chazelle \cite{C2000} found an algorithm with $O(m\ \alpha(m, n))$ complexity, where the $\alpha$ is the inverse Ackermann function.

The optimal algorithm has been discovered by Pettie and Ramachandrdan in 2002 \cite{optimal}. However the running time complexity of their algorithm is unknown. That said for the practical purposes the problem of finding the mst has been solved for many years as the textbook algorithms have really good complexities and are easy to implement. 

The algorithms presented above all work in a comparison-based model in which the edges are comparable in constant time and no bit manipulation is allowed. If the edge costs are integers and the model allows for bucketing and bit manipulation then the problem is possible to solve in $O(m + n)$ time deterministically, as presented by Fredman and Willard \cite{fredmanWillard}.

It is also possible to verify in linear time that given tree is the minimum spanning tree as shown by Komlós \cite{komlos1984}, King \cite{king1997} and Hagerup \cite{hagerup2009even}.

All of the above algorithms were deterministic, however there also exist randomized algorithms for this problem. Karger, Klein and Tarjan showed in 1995 \cite{kkt} one that runs in $O(m + n)$ expected time. Furthermore in 2005 Chazelle, Rubinfeld and Trevisan \cite{crt} devised a sublinear randomized algorithm which does not find the minimum spanning tree, but rather approximates its total weight.

\begin{table}[H]
\centering
\caption{Minimum spanning tree algorithms. Implemented algorithms highlighted in \textbf{bold}.}
\begin{tabular}{l c c c}
\toprule
\textbf{Name} & \textbf{Year} & \textbf{Complexity} & \textbf{Note} \\
\midrule
Borůvka & 1926 & $O(m\log{n})$ & \\
Kruskal & 1956 & $O(m\log{n})$ & \\
Prim & 1957 & $O(m\log{n})$ & \\
Yao & 1975 & $O(m \log\log(n))$ & \\
Fredman, Tarjan & 1984 & $O(m \beta(m, n))$ & \\
Komlós & 1984 & $O(m + n)$ & verification\\
Galil et al. & 1986 & $O(m \log\beta(m, n))$ & \\ 
Fredman, Willard & 1993 & $O(m + n)$ & bit manipulation \\
Karger, Klein, Tarjan & 1995 & $O(m + n)$ & randomized \\
King & 1997 & $O(m + n)$ & verification \\ 
\textbf{Chazelle} & \textbf{2000} & $O(m\alpha(m,n))$ & \\
Pettie, Ramachandran & 2002 & optimal & unknown complexity\\
\textbf{Chazelle et al.} & \textbf{2005} & sublinear & approximate weight \\
Hagerup & 2009 & $O(m + n)$ & verification \\
\bottomrule
\end{tabular}
\end{table}

\section{Preliminaries}

\subsection{Graphs}
\begin{definition} [Graph \cite{diesel}]
    A graph is a pair $G = (V, E)$ of sets such that $E \subseteq \binom{V}{2}$ and $V \cap E = \emptyset.$
\end{definition}
 Throughout the paper for $G = (V, E)$ we write $V(G)$ to denote $V$ -- the set of vertices (nodes or points) and $E(G)$ to denote $E$ -- the set of edges. 
 
 For any graphs $G$ and $H$ we define the following operations:
\begin{itemize}
  \item $G \cup H = (V', E')$, with $V' = V(G) \cup V(H)$ and $E' = E(G) \cup E(H)$
  \item $G \cap H = (V', E')$, with $V' = V(G) \cap V(H)$ and $E' = E(G) \cap E(H)$
  \item $G \setminus H = (V', E')$, with $V' = V(G) \setminus V(H)$ and $E' = E(G) \setminus E(H)$
\end{itemize}


\begin{definition} [Graph with loops]
 A graph with loops is a pair $G = (V, E)$ of sets such that $E \subseteq V^2$.
\end{definition}

\begin{definition} [Weighted graph]
    Graph $G = (V, E)$ is weighted if there is a function $w : E \xrightarrow{} \mathbb{R_+}$ defined on the edges of $G$. 
\end{definition}
For a given edge $e = \{u, v\}$ we denote its weight (also called cost) $w(e) = w_e = w_{uv}$.

\begin{definition}[Incident \cite{diesel}]
    A vertex $v$ is \textbf{incident} with an edge $e$ if $v\in e$.
\end{definition}
We denote by $E(v)$ set of all edges in $E$ incident with a vertex $v$.

\begin{definition}[Degree \cite{diesel}]
    The degree $d_G(v) = |E(v)|$ of a vertex $v$ is the number of edges incident with $v$.
\end{definition}
Since $G$ is often obvious from the context, we will use the notation $d(v)$ or even $d_v$.

For graphs with loops we define the vertex degree as $d(v) = |E(v)| + |\{v\colon \{v\} \in E\}]$. Loops are counted twice.

\begin{definition}[Average degree \cite{diesel}]
    The number
    \begin{equation*}
        d(G) = \frac1{|V|}\sum\limits_{v \in V}d(v)    
    \end{equation*}
    is the \textbf{average degree} of $G$.
\end{definition}
If it is clear from the context we shorten $d(G)$ to $d$.

Now let us proceed with a few auxiliary lemmas and definitions
\begin{definition}[Subgraph \cite{diesel}]
For graphs $G = (V, E), G' = (V', E')$  If $V' \subseteq V$ and $E' \subseteq E$, then $G'$ is a subgraph of $G$.
\end{definition}
We use the notation $G' \subseteq G$ to denote that $G'$ is a subgraph of $G$.

\begin{definition}[Induced subgraph \cite{diesel}]
    If $G' \subseteq G$ and $G'$ contains all the edges $\{x,y\} \in E$ with $x,y\in V$, then $G'$ is an \textbf{induced subgraph} of $G$. 
\end{definition}
We also say that $V'$ induces $G'$ in $G$.

\begin{definition}[Spanning \cite{diesel}]
    $G' \subseteq G$ is a \textbf{spanning} subgraph of $G$ if $V'$ spans all of $G$, i.e. if $V' = V$.  
\end{definition}

\begin{definition}[Cut of a graph]
    For a given graph $G = (V, E)$ if we have nonempty sets $V_1 \cup V_2 = V$ such that $V_1 \cap V_2 =\emptyset$. We call it a \textbf{cut} and the cut set is the set of edges with one endpoint in $V_1$ and one in $V_2$.
\end{definition}

\begin{definition}[Edge contraction]
    Given a graph $G = (V, E)$ and an edge $uv$ we say that a graph $G' = (V', E')$, where $V' = V(G) \setminus \{u, v\} \cup\{uv\}$ and $E' = \{e \in E: e\in V' \lor (\{w, uv\}\ \text{if}\ wu \in E \lor wv \in E) \}$ has been created through a contraction of edge $uv$.
\end{definition}

\begin{definition}[Graph minor]
    We say that graph $H$ is a minor of graph $G$ if it can be obtained through a sequence of edge contractions beginning with graph $G$.
\end{definition}

\begin{definition}[Path \cite{diesel}]
    A path is a non-empty graph $P = (V,E)$ of the form $V = \{x_0, x_1, ..., x_k\}, E = \{x_0x_1, x_1x_2, ...,x_{k-1}x_k\}$, where $x_i$ are all distinct.   
\end{definition}
The vertices $x_0$ and $x_k$ are \textbf{connected} by $P$ and are called \textbf{ends}.
Throughout the paper we use the notation $P = x_0...x_{k-1}$.

\begin{definition}[Cycle \cite{diesel}]
    If $P = x_0...x_{k-1}$ is a path and $k\geq 3$, then the graph $C := P + x_{k-1}x_0$ is called a \textbf{cycle}.
\end{definition}
Throughout the paper we use the notation $C = x_0...x_{k-1}x_0$.

\begin{definition}[Connected graph \cite{diesel}]
    A graph is called \textbf{connected} if it is non-empty and any two of its vertices are linked by a path in $G$.
\end{definition}

\begin{definition}[Connected component \cite{diesel}]
Let $G = (V, E)$ be a graph. A maximal connected subgraph of $G$ is a \textbf{connected component} of $G$.    
\end{definition}
The components are induced subgraphs and their vertex sets partition $V$.

\begin{definition}[Forest, tree \cite{diesel}]
    An acyclic graph, one not containing any cycles, is called a \textbf{forest}. A connected forest is called a \textbf{tree}.
\end{definition}

\begin{definition}[Leaves, inner vertices \cite{diesel}]
    The vertices of degree 1 in a tree are its \textbf{leaves}, the others are its \textbf{inner vertices}.
\end{definition}

\begin{definition}[Root, rooted tree \cite{diesel}]
    A tree $T$ with one vertex marked as \textbf{root} is called a \textbf{rooted tree}.
\end{definition}

\begin{definition}[Tree cost]
    Cost (also called weight) $w(T)$ of a weighted tree $T$ is the sum of costs of its edges. That is $w(T) = \sum\limits_{e\in E(T)}w_e$.
\end{definition}

\subsection{Minimum spanning tree}
\begin{definition}[Minimum spanning tree]
    Minimum spanning tree of a graph $G$, denoted as $MST(G)$, is a spanning tree with the minimum cost of all of the spanning trees of $G$.
\end{definition}
We will also write $MST$ when the $G$ is known from the context.

\begin{definition}[Minimum spanning tree weight]
For a given graph $G$ let $M(G) = w(MST(G))$ be the weight of its minimum spanning tree.
\end{definition}

\begin{problem}[Minimum spanning tree problem -- optimization]
    For a given graph $G$ find and output the $MST(G)$.
\end{problem}

\begin{problem}[Minimum spanning tree problem -- decision]
    For a given graph $G$ and a number $k$ find a spanning tree $T$ of $G$ such that $w(T) \le k$.
\end{problem}

Following properties assume that the graph $G$ has distinct edge weights:
\begin{theorem} [Strong cut property \cite{eisner}]
\label{cut-property}
For every graph $G$ it holds that $e \in MST(G) \iff e$ is the lightest edge across some cut of $G$.
\end{theorem}
\begin{theorem} [Strong cycle property \cite{eisner}]
\label{cycle-property}
For every graph $G$ it holds that $e \not\in MST(G) \iff e$ is the heaviest edge on some cycle of $G$.
\end{theorem}
Here is the proof of both properties at once due to Eisner \cite{eisner}.
\begin{proof}
    $(\Rightarrow)$ Every $e$ when removed from $MST(G)$ determines a cut across which it is lightest as if there was a lighter edge $e'$ in the cut-set then $MST(G) - e + e'$ would have a smaller weight. Every $e \not\in MST(G)$, when added to the MST(G) creates a cycle on which it is heaviest as if there was a heavier edge $e'$ on the cycle, then once again we would have a contradiction with $MST(G) - e + e'$.

    $(\Leftarrow)$
    We derive contrapositives from the cases just proved. If $e \not\in MST(G)$ then it is a heaviest edge on some cycle and it cannot be the lightest in any cut-set as the cut set would have to intersect the cycle. If $e \in MST(G)$ then it is the lightest in some cut set, so it cannot be the heaviest on any cycle as it would have to have a non empty intersection with the cut-set on which $e$ is the lightest.
\end{proof}

\begin{theorem} [Minimum spanning tree uniqueness]
    If a connected graph $G$ has distinct edge costs then it has exactly one minimum spanning tree.
\end{theorem}
\begin{proof}
Both strong cut property and strong cycle property classify edges into the ones in MST and outside the MST.
\end{proof}