\section{Algorithm details}
Although both algorithms share a common idea and both use the algorithm from Chapter 3 to divide the graph into regions, they take different approaches. There are two main differences between Frederickson's and Henzinger's algorithms. First, Henzinger's algorithm operates on \emph{directed} planar graphs, which makes it more general. Second, both algorithms manage heap updates in entirely different ways. For contrast, Frederickson's algorithm stores all boundary vertices in a single, cleverly organized heap throughout the main search phase. Henzinger's algorithm maintains multiple heaps and updates them in a more controlled and distributed manner.

Henzinger's algorithm has a shorter "attention span" than Frederickson's algorithm. The latter processes regions in complete phases, similar to Dijkstra's algorithm. In contrast, Henzinger's algorithm may stop the search phase in a region before it is fully completed, often switching focus between regions as the computation proceeds.

One further difference between the two algorithms is the number of layers in the division scheme. In contrast to Frederickson's approach, Henzinger's algorithm employs three levels of division: a trivial level 0, where each region consists of a single edge; a nontrivial level defined by the parameter $r$, analogous to Frederickson’s main division; and level 2, where the entire graph forms a single region.

\subsection{Priority queue}
During the main part the Henzinger's algorithm makes use of priority queues. The structure of size $n$ must support following operations in a given time bound \cite{henzinger}:
\begin{itemize}
    \item $\textsc{update}(Q, x, k)$ which updates the key of $x$ to $k$ in $O(\log n)$,
    \item $\textsc{minItem}(Q)$, which returns the item in $Q$ with the minimum key in $O(1)$,
    \item $\textsc{minKey}(Q)$, which returns the key associated with $\textsc{minItem}(Q)$ in $O(1)$.
\end{itemize}

We will denote by $Q(R)$ the priority queue associated with region $R$. During the algorithm, all keys are initialized with $\infty$ which means all items are inactive. The data structure can also allow for the removal of vertices from the priority queue once they are inactive.

\subsection{Algorithm and proof of correctness}

As mentioned before in the first part, the algorithm uses strategy from Chapter 2 to divide graph into level 1 regions of size $r = O(\log^4n)$ with $\sqrt{r} = O(\log^2 n)$ boundary nodes per region. It was proven that such division can be achieved in $$O(n \log r + (n/\sqrt{r})\log n) = O(n\log \log n + n/\log n) = O(n \log \log n)$$ which is exactly time complexity proposed by Monica Henzinger \cite{henzinger}.

Now we can briefly describe the main search phase of the algorithm, assuming the division has already been created. Before the algorithm starts, we initialize $d[v] = \infty$ for all vertices and $d[s] = 0$ for the source node $s$. For each region, a priority queue is created to store the distance for each node and a  main priority queue is used to store the minimum distance per region.

The algorithm proceeds in two steps. In step 1, a region containing a node with the smallest $d[v]$ and active edges is selected. Then, step 2 is executed either $\log n$ times or until there are no active edges remaining in the region. In step 2, which operates within a single region, we select the node with the smallest $d[v]$ and active edges (similarly to Dijkstra's algorithm), relax all its active edges within the region, and update the relevant priority queues whenever any value changes.

To prove the complexity of the algorithm, we will introduce some new definitions.
\begin{defn}(atomic region)
For and edge $u v$ an \emph{atomic region} is a graph region that consists only of two nodes $u$ and $v$ and can be associated with single directed edge $(u,v)$. We will denote \emph{atomic region} as $R(u v)$. This type of regions will be called level 0 region.
\end{defn}

We can transform our division in linear time into division that consists of 3 separate levels. Level 0 regions are atomic regions and there exists one atomic region for every directed edge of graph $G$. Level 1 regions will be regions generated by strategy from Chapter 2. Due to how regions were defined both vertices of any level 0 region always share at least one level 1 region. By level 2 region we will denote region $R_G$ that consists of the whole graph. There is a clear relations ship between region levels. Level $i$ region is always fully contained inside some level $(i+1)$ region. For a level $i$ region $R$ all level $(i-1)$ regions that are fully contained inside it will be called \emph{children of region $R$} (with an analogous definition for \emph{parent} of a region R). The algorithm makes use of two parameters $\alpha_2 = 1$ and $\alpha_1 = \log n$ which intuitively limit the attention span of the algorithm on each level of division. By $l(R)$ we will denote level of a region $R$. Before running the algorithm for all vertices $v$ we initialize $d[v]$ and all keys of priority queues with $\infty$.

\begin{algorithm}
\caption{\textsc{SimplifiedHenzingerSSSP}}\label{henzingerFormal}
\begin{algorithmic}[1]
\Require Planar graph $G=(V,E, w)$, source node $s$, leveled division $D$
\Ensure Shortest path distances $d[v]$ from $s$ to all $v \in V$

\Procedure{SimplifiedHenzingerSSSP}{$G$, $s$, $D$}
    \State $d[s] \gets 0$
    \ForAll{edges $(s, x)$}
        \State \Call{UpdateGlobal}{$R(s x)$, $(s, x)$, 0}
    \EndFor
    \While{$\textsc{minKey}(Q(R_G)) < \infty$}
        \State \Call{Process}{$R_G$}
    \EndWhile
\EndProcedure
\State
\Procedure{Process}{region $R$}
    \If{$R$ contains a single edge $(u, v)$}
        \If{$d[v] > d[u] + w(u, v)$}
            \State $d[v] \gets d[u] + w(u, v)$
            \ForAll{outgoing edges $(v, x)$ of $v$}
                \State \Call{UpdateGlobal}{$R(v x)$, $(v, x)$, $d[v]$}
            \EndFor
        \EndIf
        \State \textsc{updateKey}$(Q(R), (u, v), \infty)$
    \Else
        \RepeatN{ $\alpha_{l(R)}$} \Comment{ $l(R)$ denotes level of region $R$}
            \If{$\textsc{minKey}(Q(R)) = \infty$}
            \State \textbf{break}
            \EndIf
            \State $R^* \gets \textsc{minItem}(Q(R))$
            \State \Call{Process}{$R^*$}
            \State \textsc{updateKey}$(Q(R), R^*, \textsc{minKey}(Q(R^*)))$
        \End
    \EndIf
\EndProcedure
\State
\Procedure{UpdateGlobal}{region $R$, item $x$, key $k$}
    \State $before \gets$ \textsc{minKey}$(Q(R))$
    \State \textsc{update}$(Q(R), x, k)$
    \State $after \gets$ \textsc{minKey}$(Q(R))$
    \If{$before \neq after$}
    \State \textsc{UpdateGlobal}$(parent(R), R, \textsc{minKey}(Q(R)))$
    \EndIf
\EndProcedure

\end{algorithmic}
\end{algorithm}

Recursive version of the algorithm significantly simplifies the proofs and better shows the nature of the algorithm.
In Chapter 5 we will propose version of \Cref{henzingerFormal} that significantly reduces number of recursive calls.

Now we can move on to prove the correctness of the algorithm. It is a known fact that for SSSP algorithm to be correct three conditions must be satisfied:
\begin{itemize}
    \item $d[s] = 0$ for the source vertex $s$.
    \item For every vertex $v$, $d[v]$ must be an upper bound of and actual distance from $s$ to $v$
    \item For every edge $(u, v)$ inequality $d[v] \leq d[u] + w(u,v)$ holds. Edge that satisfies inequality if called \emph{relaxed edge}.
\end{itemize}

The following lemmas are necessary to prove that all conditions holds.

\begin{lemma}[Lemma 3.1. in \cite{henzinger}]
\label{condition2}
For every vertex $v$ during the algorithm $d[v]$ is always greater or equal to the actual distance from $s$ to $v$.
\end{lemma}
\begin{proof}
By induction on the number of steps of the algorithm. We state that the invariant holds during the entire run of the algorithm. Initially all vertices are labeled with $\infty$ and source vertex $s$ is labeled by $0$, the lemma is obviously true. The only steps of the algorithm that requires verification is moment when some edge $(u, v)$ is relaxed. By induction $d[u]$ is an upper bound of distance from $s$ to $u$ so $d[v] + w(u,v)$ is an upper bound of distance from $s$ to $v$

\end{proof}
We say that edge $(u, v)$ is active when the key of $(u, v)$ in priority queue $Q(R(u v))$ is not an infinity.

\begin{lemma} [Lemma 3.2. in \cite{henzinger}]
\label{relaxed}
If an edge $(u, v)$ during an algorithm is inactive it is also relaxed.
\end{lemma}
\begin{proof}
The lemma holds before first step 1 of the algorithm begins as all vertices are initialized with $\infty$ and only edges from source node $s$ are active. During the algorithm values of $d[v]$ can only decrease, thus an edge $u v$ can stop being relaxed only when $d[u]$ changes. If $d[u]$ changes than key in all priority queues that contain the $u$ vertex is also updated. This means that edge is active when is not relaxed. This by contraposition proves the lemma. 
\end{proof}

\begin{lemma}
\label{all}
Once the algorithm terminates all edges are inactive.
\end{lemma}
\begin{proof}
The key in the priority queue of a parent region is updated whenever one of its child regions obtains a new minimum key, and also whenever the child region with the current minimum key is processed. This ensures that the key representing a child region in the parent’s priority queue is never equal to $\infty$ as long as there exists at least one child region with a key not equal to $\infty$.

Clearly when algorithm runs there must exist at least one region which priority queue has a key smaller than infinity. From how we define active edges it means that during the algorithm there must be an active edge and algorithm terminates once there are no more active edges.
\end{proof}

\begin{theorem}
\Cref{henzingerFormal} correctly calculates all distances from source vertex $s$ to all vertices in the planar graph.
\end{theorem}

\begin{proof}
The first condition follows directly from the fact that $d[s]$ is initialized with $0$ and all edges have non-negative edge weights so during the algorithm $d[s]$ remains unchanged. The second condition follows directly from  \Cref{condition2}. The third condition is a direct conclusion from  \Cref{relaxed} and \Cref{all}
\end{proof}
